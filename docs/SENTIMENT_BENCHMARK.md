# üéØ Sentiment Analysis Benchmark

## M·ª•c ƒë√≠ch
So s√°nh 4 models ƒë·ªÉ ch·ªçn model t·ªët nh·∫•t cho sentiment analysis:
1. **Logistic Regression** (ML classical)
2. **Linear SVM** (ML classical)
3. **RoBERTa** (Deep Learning)
4. **VADER** (Rule-based)

## C√°ch ch·∫°y

### 1. C√†i dependencies
```bash
pip install vaderSentiment scikit-learn transformers torch
```

### 2. Ch·∫°y benchmark
```bash
python scripts/run_benchmark.py
```

## Ti√™u ch√≠ ƒë√°nh gi√°

### Metrics
- **Accuracy**: ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ
- **F1 Score**: C√¢n b·∫±ng gi·ªØa precision v√† recall
- **Speed**: Th·ªùi gian x·ª≠ l√Ω (ms/review)

### Weighted Score
```
Total Score = 50% Accuracy + 30% F1 + 20% Speed
```

## K·∫øt qu·∫£ d·ª± ki·∫øn

| Model | Accuracy | F1 Score | Speed (ms) | Pros | Cons |
|-------|----------|----------|------------|------|------|
| **Logistic** | ~85-88% | ~0.85 | 0.5-2ms | Fast, simple, interpretable | Need training data |
| **SVM** | ~86-89% | ~0.86 | 1-3ms | High accuracy, robust | Slower than Logistic |
| **RoBERTa** | ~92-95% | ~0.93 | 100-500ms | Best accuracy | Very slow, GPU needed |
| **VADER** | ~78-82% | ~0.78 | 0.1-0.5ms | Ultra fast, no training | Lower accuracy |

## Recommendation

### Cho Production (Real-time)
- **VADER** n·∫øu c·∫ßn speed t·ªëi ƒëa
- **Logistic/SVM** n·∫øu c·∫ßn balance speed + accuracy

### Cho Batch Processing
- **RoBERTa** n·∫øu c·∫ßn accuracy cao nh·∫•t
- **SVM** n·∫øu c·∫ßn balance t·ªët

### Cho Project n√†y
Recommend: **Linear SVM** ho·∫∑c **Logistic Regression**
- Accuracy ƒë·ªß t·ªët (~87%)
- Speed nhanh (~1-2ms)
- D·ªÖ deploy, kh√¥ng c·∫ßn GPU
- C√≥ th·ªÉ train tr√™n data ri√™ng

## Implementation

Sau khi ch·ªçn model, integrate v√†o `sentiment_node.py`:

```python
# Load trained model
import joblib
model = joblib.load('models/sentiment_svm.pkl')
vectorizer = joblib.load('models/tfidf_vectorizer.pkl')

# Predict
def predict_sentiment(text):
    text_vec = vectorizer.transform([text])
    prediction = model.predict(text_vec)[0]
    return prediction  # 'positive', 'negative', 'neutral'
```

## Notes

- RoBERTa ƒë∆∞·ª£c sample (500 reviews) v√¨ qu√° ch·∫≠m
- Ground truth labels t·ª´ Rating: 1-2‚òÖ = negative, 3‚òÖ = neutral, 4-5‚òÖ = positive
- Models ƒë∆∞·ª£c train tr√™n 80% data, test tr√™n 20%
- VADER kh√¥ng c·∫ßn training, ch·∫°y tr·ª±c ti·∫øp

## Next Steps

1. ‚úÖ Ch·∫°y benchmark
2. ‚è≥ Pick best model
3. ‚è≥ Save trained model
4. ‚è≥ Integrate v√†o `sentiment_node.py`
5. ‚è≥ Update API
6. ‚è≥ Test performance
